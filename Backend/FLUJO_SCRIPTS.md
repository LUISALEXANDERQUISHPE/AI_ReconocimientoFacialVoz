# ðŸ“Š **FLUJO COMPLETO DE SCRIPTS - SISTEMA PROFESIONAL**

## ðŸ”„ **DIAGRAMA DE FLUJO GENERAL**

```
ðŸ“¸ CAPTURA â†’ ðŸ”§ PROCESAMIENTO â†’ ðŸ§  ENTRENAMIENTO â†’ ðŸŽ¯ RECONOCIMIENTO
     â”‚              â”‚                â”‚                 â”‚
     â–¼              â–¼                â–¼                 â–¼
   Crudo         Normalizado      Modelo H5        Tiempo Real
```

---

## ðŸ“‹ **FLUJO DETALLADO POR ETAPAS**

### **ETAPA 1: ðŸ“¸ CAPTURA DE DATASET**

#### **OpciÃ³n A: Captura Original (USADO ANTERIORMENTE)**
```bash
python 03_capturar_dataset.py
```
**Flujo interno:**
1. Solicita nombre de persona
2. Graba video 40 segundos con cÃ¡mara
3. Detecta rostros con Haar Cascades bÃ¡sico
4. Extrae 100 frames distribuidos uniformemente
5. Recorta rostros con mÃ¡rgenes bÃ¡sicos
6. Guarda imÃ¡genes directamente en `dataset/`

#### **OpciÃ³n B: Captura Profesional (NUEVA)**
```bash
python 03_capturar_dataset_profesional.py
```
**Flujo interno mejorado:**
1. Solicita nombre de persona
2. Configura cÃ¡mara en alta resoluciÃ³n (1280x720, 30fps)
3. Graba video con detecciÃ³n avanzada (Haar + soporte DNN)
4. Filtra frames por calidad (desenfoque, iluminaciÃ³n)
5. Aplica detecciÃ³n con umbrales de confianza
6. Extrae rostros con mÃ¡rgenes adaptativos (30%)
7. Guarda en `dataset_raw/` con metadatos completos

---

### **ETAPA 2: ðŸ”§ PROCESAMIENTO DE IMÃGENES**

```bash
python 03b_procesar_imagenes.py --all
# o
python 03b_procesar_imagenes.py "Nombre_Persona"
```

**Flujo de procesamiento:**
```
dataset_raw/[Persona]/*.jpg
         â”‚
         â–¼
    ðŸ” AnÃ¡lisis de Calidad
    â”œâ”€â”€ MediciÃ³n de desenfoque (Laplaciano)
    â”œâ”€â”€ AnÃ¡lisis de brillo/contraste  
    â”œâ”€â”€ DetecciÃ³n de sobre/sub exposiciÃ³n
    â”œâ”€â”€ ValidaciÃ³n de detecciÃ³n facial
    â””â”€â”€ Score global (0-100)
         â”‚
         â–¼
    âœ¨ Mejora de Imagen
    â”œâ”€â”€ CLAHE (equalizaciÃ³n adaptativa)
    â”œâ”€â”€ Filtro bilateral (reducciÃ³n ruido)
    â”œâ”€â”€ Ajuste de contraste/brillo
    â””â”€â”€ NormalizaciÃ³n facial a 160x160px
         â”‚
         â–¼
    ðŸŽ² Data Augmentation (si calidad >60)
    â”œâ”€â”€ Imagen original mejorada
    â”œâ”€â”€ RotaciÃ³n ligera (-10Â° a +10Â°)
    â”œâ”€â”€ Ajuste de brillo (Â±20%)
    â””â”€â”€ Flip horizontal
         â”‚
         â–¼
    ðŸ’¾ Guardado en dataset/[Persona]/
    â”œâ”€â”€ [nombre]_processed.jpg (original mejorada)
    â”œâ”€â”€ [nombre]_rotated.jpg
    â”œâ”€â”€ [nombre]_brightness.jpg
    â”œâ”€â”€ [nombre]_flipped.jpg
    â””â”€â”€ processing_report.json (metadatos)
```

---

### **ETAPA 3: ðŸ§  ENTRENAMIENTO DEL MODELO**

```bash
python 04_entrenar_modelo.py
```

**Flujo de entrenamiento:**
```
dataset/[Todas_Personas]/*.jpg
         â”‚
         â–¼
    ðŸ“‚ Carga de ImÃ¡genes
    â”œâ”€â”€ Escanea todas las carpetas de personas
    â”œâ”€â”€ Filtra extensiones vÃ¡lidas (.jpg, .png, etc.)
    â””â”€â”€ Carga imÃ¡genes con OpenCV
         â”‚
         â–¼
    ðŸ‘¤ DetecciÃ³n de Rostros
    â”œâ”€â”€ Aplica Haar Cascades
    â”œâ”€â”€ Selecciona rostro mÃ¡s grande por imagen
    â””â”€â”€ Valida tamaÃ±o mÃ­nimo (30x30px)
         â”‚
         â–¼
    ðŸ”¢ ExtracciÃ³n de CaracterÃ­sticas
    â”œâ”€â”€ Redimensiona rostro a 64x64px
    â”œâ”€â”€ Convierte a escala de grises
    â”œâ”€â”€ Aplica ecualizaciÃ³n de histograma
    â”œâ”€â”€ Suaviza con filtro Gaussiano
    â”œâ”€â”€ Divide en regiones 8x8 (64 regiones)
    â”œâ”€â”€ Calcula estadÃ­sticas por regiÃ³n (media, desv.std)
    â”œâ”€â”€ Agrega estadÃ­sticas globales
    â””â”€â”€ Normaliza vector a 128 caracterÃ­sticas
         â”‚
         â–¼
    ðŸ·ï¸ PreparaciÃ³n de Etiquetas
    â”œâ”€â”€ Codifica nombres a nÃºmeros (LabelEncoder)
    â”œâ”€â”€ Convierte a categorical (one-hot encoding)
    â””â”€â”€ Valida mÃ­nimo 2 clases
         â”‚
         â–¼
    ðŸ§  ConstrucciÃ³n del Modelo (Keras)
    â”œâ”€â”€ Input: 128 caracterÃ­sticas
    â”œâ”€â”€ Dense(256) + BatchNorm + Dropout(0.3)
    â”œâ”€â”€ Dense(128) + BatchNorm + Dropout(0.3)  
    â”œâ”€â”€ Dense(64) + Dropout(0.2)
    â””â”€â”€ Dense(num_clases) + Softmax
         â”‚
         â–¼
    ðŸŽ¯ Entrenamiento
    â”œâ”€â”€ Optimizador: Adam (lr=0.001)
    â”œâ”€â”€ Loss: Categorical Crossentropy
    â”œâ”€â”€ Epochs: Adaptativo (min 20, max 1000)
    â”œâ”€â”€ Batch Size: Adaptativo (4-32)
    â”œâ”€â”€ ValidaciÃ³n: 10% de datos
    â”œâ”€â”€ EarlyStopping (patience=10)
    â””â”€â”€ ReduceLROnPlateau (patience=5)
         â”‚
         â–¼
    ðŸ’¾ Guardado
    â”œâ”€â”€ modelo_rostros.h5 (arquitectura + pesos)
    â””â”€â”€ clases.npy (mapeo nombre-Ã­ndice)
```

---

### **ETAPA 4: ðŸŽ¯ RECONOCIMIENTO EN TIEMPO REAL**

```bash
python 05_reconocimiento_tiempo_real.py
```

**Flujo de reconocimiento:**
```
ðŸŽ¥ CÃ¡mara en Vivo
         â”‚
         â–¼
    ðŸ“¹ Captura de Frame
    â”œâ”€â”€ Lee frame de cÃ¡mara
    â””â”€â”€ Convierte a escala de grises
         â”‚
         â–¼
    ðŸ‘¤ DetecciÃ³n de Rostros
    â”œâ”€â”€ Aplica Haar Cascades
    â”œâ”€â”€ Filtro: minSize=(60,60)
    â””â”€â”€ Para cada rostro detectado:
         â”‚
         â–¼
    ðŸ”¢ ExtracciÃ³n de CaracterÃ­sticas
    â”œâ”€â”€ MISMA funciÃ³n que entrenamiento
    â”œâ”€â”€ Redimensiona rostro a 64x64px
    â”œâ”€â”€ Procesa con pipeline idÃ©ntico
    â””â”€â”€ Genera vector de 128 caracterÃ­sticas
         â”‚
         â–¼
    ðŸ§  PredicciÃ³n
    â”œâ”€â”€ Carga modelo_rostros.h5
    â”œâ”€â”€ Carga clases.npy
    â”œâ”€â”€ Ejecuta model.predict()
    â””â”€â”€ Obtiene probabilidades por clase
         â”‚
         â–¼
    ðŸŽ¯ InterpretaciÃ³n de Resultados
    â”œâ”€â”€ Confianza > 80%: Verde "Persona" 
    â”œâ”€â”€ Confianza 50-80%: Amarillo "Posible Persona?"
    â”œâ”€â”€ Confianza < 50%: Rojo "Desconocido"
    â””â”€â”€ Dibuja rectÃ¡ngulo + texto en video
         â”‚
         â–¼
    ðŸ“º VisualizaciÃ³n
    â”œâ”€â”€ Muestra frame con anotaciones
    â”œâ”€â”€ Loop continuo hasta 'Q'
    â””â”€â”€ Libera recursos al salir
```

---

## ðŸ” **SCRIPTS DE VERIFICACIÃ“N Y UTILIDADES**

### **VerificaciÃ³n Visual del Dataset**
```bash
python verificar_dataset.py reporte        # Reporte general
python verificar_dataset.py muestra        # Muestra visual de todas las personas  
python verificar_dataset.py comparar "Edison Fiallos" 5  # Antes vs despuÃ©s
```

### **MigraciÃ³n de Dataset Existente**
```bash
python migrar_dataset.py
```
**Flujo:**
1. Lee dataset existente en `dataset/`
2. Copia a `dataset_raw/` con nomenclatura nueva
3. Respalda original en `dataset_backup_YYYYMMDD_HHMMSS/`
4. Genera `migration_report.json`

### **Descarga de Modelos DNN (Opcional)**
```bash
python descargar_modelos_dnn.py
```

---

## âš¡ **FLUJO COMPLETO RECOMENDADO**

### **Para NUEVO dataset:**
```bash
# 1. Capturar persona por persona
python 03_capturar_dataset_profesional.py  

# 2. Procesar todas las imÃ¡genes
python 03b_procesar_imagenes.py --all

# 3. Verificar calidad
python verificar_dataset.py reporte

# 4. Entrenar modelo
python 04_entrenar_modelo.py

# 5. Probar en tiempo real
python 05_reconocimiento_tiempo_real.py
```

### **Para dataset EXISTENTE (YA EJECUTADO):**
```bash
# âœ… 1. MigraciÃ³n (YA HECHO)
python migrar_dataset.py  

# âœ… 2. Procesamiento (YA HECHO)
python 03b_procesar_imagenes.py --all

# 3. Entrenamiento con datos mejorados
python 04_entrenar_modelo.py

# 4. Reconocimiento mejorado
python 05_reconocimiento_tiempo_real.py
```

---

## ðŸ“Š **ARCHIVOS GENERADOS EN EL FLUJO**

```
Backend/
â”œâ”€â”€ dataset_raw/                    # ðŸ“¸ ImÃ¡genes crudas de captura
â”‚   â””â”€â”€ [Persona]/
â”‚       â”œâ”€â”€ *.jpg
â”‚       â””â”€â”€ capture_metadata.txt
â”‚
â”œâ”€â”€ dataset/                        # ðŸ”§ ImÃ¡genes procesadas listas
â”‚   â””â”€â”€ [Persona]/  
â”‚       â”œâ”€â”€ *_processed.jpg         # Imagen principal normalizada
â”‚       â”œâ”€â”€ *_rotated.jpg           # AugmentaciÃ³n rotaciÃ³n  
â”‚       â”œâ”€â”€ *_brightness.jpg        # AugmentaciÃ³n brillo
â”‚       â”œâ”€â”€ *_flipped.jpg           # AugmentaciÃ³n flip
â”‚       â””â”€â”€ processing_report.json  # Metadatos de calidad
â”‚
â”œâ”€â”€ modelo_rostros.h5               # ðŸ§  Modelo entrenado
â”œâ”€â”€ clases.npy                      # ðŸ·ï¸ Mapeo de nombres
â”œâ”€â”€ migration_report.json           # ðŸ“‹ Reporte de migraciÃ³n
â””â”€â”€ dataset_backup_*/               # ðŸ’¾ Backup del dataset original
```

---

## ðŸŽ¯ **TU ESTADO ACTUAL**

âœ… **Completado:**
- MigraciÃ³n del dataset existente  
- Procesamiento profesional de 2,400 imÃ¡genes
- Calidad promedio: 87.0/100
- Dataset listo para entrenamiento

ðŸ”„ **Siguiente paso:**
```bash
python 04_entrenar_modelo.py
```

Â¡El flujo estÃ¡ optimizado para mÃ¡xima calidad y profesionalismo! ðŸš€